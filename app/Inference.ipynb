{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import XLMTokenizer, RobertaModel\n",
    "from herbert_emotion_classifier.model import HerbertEmotionClassifier\n",
    "from herbert_emotion_classifier.seq_model import HerbertEmotionSequenceClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = XLMTokenizer.from_pretrained(\"allegro/herbert-klej-cased-tokenizer-v1\")\n",
    "bert_model = RobertaModel.from_pretrained(\"allegro/herbert-klej-cased-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict_path= \"dense_model.pth\"\n",
    "\n",
    "# classification_model = HerbertEmotionClassifier()\n",
    "# classification_model.load_state_dict(torch.load(PATH), strict=False)\n",
    "# classification_model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH= \"wust_seq_model.pth\"\n",
    "\n",
    "new_model = HerbertEmotionSequenceClassifier()\n",
    "new_model.load_state_dict(torch.load(PATH), strict=False)\n",
    "new_model = new_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([768])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"Jest w pytę\"\n",
    "\n",
    "with torch.no_grad():\n",
    "    encoded_input = tokenizer.encode(text, return_tensors='pt').to(\"cpu\")\n",
    "    outputs = bert_model(encoded_input)\n",
    "    sentence_embedding = outputs[1].squeeze(dim=0)\n",
    "sentence_embedding.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_dict = {\n",
    "    0: \"oczekiwanie\",\n",
    "    1: \"podziw\",\n",
    "    2: \"radosc\",\n",
    "    3: \"smutek\",\n",
    "    4: \"strach\",\n",
    "    5: \"wstret\",\n",
    "    6: \"zaskoczenie\",\n",
    "    7: \"zlosc\",\n",
    "    8: \"neutralny\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Softmax\n",
    "\n",
    "softmax = Softmax(dim=1)\n",
    "\n",
    "# def predict_emotion(embeddng: torch.tensor):\n",
    "#     predictions = classification_model(embeddng.unsqueeze(0))\n",
    "#     predictions = softmax(predictions).squeeze(0)\n",
    "#     predictions = predictions.tolist()\n",
    "    \n",
    "#     predicted_emotions = {}\n",
    "    \n",
    "#     for pred, emotion in zip(predictions, emotion_dict.values()):\n",
    "#         predicted_emotions[emotion] = pred\n",
    "    \n",
    "#     return predicted_emotions\n",
    "    \n",
    "# predict_emotion(sentence_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict\n",
    "\n",
    "DEVICE = \"cpu\"\n",
    "\n",
    "\n",
    "def merge(sequences: List[torch.tensor]):\n",
    "        lengths = [len(seq) for seq in sequences]\n",
    "        vector_size=768\n",
    "        padded_seqs = torch.zeros(len(sequences), max(lengths), vector_size)\n",
    "        for i, seq in enumerate(sequences):\n",
    "            end = lengths[i]\n",
    "            padded_seqs[i, (max(lengths) - end):] = seq[:end]\n",
    "        return padded_seqs\n",
    "\n",
    "@torch.no_grad()\n",
    "def get_embedding_for_list_of_texts(list_of_texts: List[str]) -> (torch.tensor, torch.tensor):\n",
    "    \"\"\"\n",
    "    For a given list of sentences the function return embedding generated by BERT\n",
    "    :param text: Sentence for which u want to get an embedding\n",
    "    :return: (tensor of embeddings for each token in sentneces, average embedding of a sentences)\n",
    "    \"\"\"\n",
    "    tokenizer = XLMTokenizer.from_pretrained(\"allegro/herbert-klej-cased-tokenizer-v1\")\n",
    "    bert_model = RobertaModel.from_pretrained(\"allegro/herbert-klej-cased-v1\")\n",
    "\n",
    "    list_of_sentence_embeddings = []\n",
    "    list_of_sequence_embeddings = []\n",
    "\n",
    "    for text in list_of_texts:\n",
    "        encoded_input = tokenizer.encode(text, return_tensors=\"pt\").to(DEVICE)\n",
    "        outputs = bert_model(encoded_input)\n",
    "\n",
    "        sequence_tokens_embedding = outputs[0].squeeze(dim=0)\n",
    "        sentence_embedding = outputs[1].squeeze(dim=0)\n",
    "\n",
    "        list_of_sequence_embeddings.append(sequence_tokens_embedding)\n",
    "        list_of_sentence_embeddings.append(sentence_embedding)\n",
    "        \n",
    "    seq_embeddings_tensor = merge(list_of_sequence_embeddings)\n",
    "    sentence_embeddings_tensor = torch.stack(list_of_sentence_embeddings, dim=0)\n",
    "\n",
    "    return seq_embeddings_tensor, sentence_embeddings_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_texts = [\"Jebać pis\", \"Kurwa jest w pytę !!!! serio jest zajebiscie\", \"Kurwa jest w pytę !!!!\", \"Kurwa jest w pytę !!!!\"]\n",
    "\n",
    "seq_embeddings_tensor, sequence_embeddings_tensor = get_embedding_for_list_of_texts(list_of_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 9])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model(seq_embeddings_tensor).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_emotion(seq_embeddings_tensor: torch.tensor) -> Dict:\n",
    "    \"\"\"\n",
    "    Function applies emotion classification mode to the given embedding\n",
    "    :param sentence_embedding: embedding averaged over all tokens, of size (N, 768)\n",
    "    :return: list of dictionaries with a probability distribution over emotions [{\"radość: 0.2137, smutek:0.01 ....}, ..] of len N\n",
    "    \"\"\"\n",
    "    classification_model = HerbertEmotionClassifier()\n",
    "    classification_model.load_state_dict(torch.load(state_dict_path), strict=False)\n",
    "    classification_model = classification_model.eval().to(DEVICE)\n",
    "\n",
    "    softmax = Softmax(dim=1)\n",
    "\n",
    "    predictions = classification_model(sentence_embeddings_tensor)\n",
    "    predictions = softmax(predictions).detach()\n",
    "    \n",
    "    list_of_predicted_emotions = []\n",
    "    \n",
    "    for pred in predictions:\n",
    "        predicted_emotions = {}\n",
    "        \n",
    "        for label_num, emotion in zip(pred.tolist(), emotion_dict.values()): \n",
    "            predicted_emotions[emotion] = label_num\n",
    "            \n",
    "        list_of_predicted_emotions.append(predicted_emotions)\n",
    "    \n",
    "    return list_of_predicted_emotions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict_path= \"wust_seq_model.pth\"\n",
    "\n",
    "def predict_emotions_with_seq_model(sentence_embeddings_tensor: torch.tensor) -> Dict:\n",
    "    \"\"\"\n",
    "    Function applies emotion classification mode to the given embedding\n",
    "    :param sentence_embedding: embedding averaged over all tokens, of size (N, 768)\n",
    "    :return: list of dictionaries with a probability distribution over emotions [{\"radość: 0.2137, smutek:0.01 ....}, ..] of len N\n",
    "    \"\"\"\n",
    "    seq_classification_model = HerbertEmotionSequenceClassifier()\n",
    "    seq_classification_model.load_state_dict(torch.load(state_dict_path), strict=False)\n",
    "    seq_classification_model = seq_classification_model.eval().to(DEVICE)\n",
    "\n",
    "    softmax = Softmax(dim=1)\n",
    "\n",
    "    predictions = seq_classification_model(sentence_embeddings_tensor)\n",
    "    predictions = softmax(predictions).detach()\n",
    "\n",
    "    list_of_predicted_emotions = []\n",
    "\n",
    "    for pred in predictions:\n",
    "        predicted_emotions = {}\n",
    "\n",
    "        for label_num, emotion in zip(pred.tolist(), emotion_dict.values()):\n",
    "            predicted_emotions[emotion] = label_num\n",
    "\n",
    "        list_of_predicted_emotions.append(predicted_emotions)\n",
    "\n",
    "    return list_of_predicted_emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = predict_emotions_with_seq_model(seq_embeddings_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'oczekiwanie': 0.014855558052659035, 'podziw': 0.002206078264862299, 'radosc': 0.0004334972763899714, 'smutek': 0.015141263604164124, 'strach': 1.0492610272194725e-05, 'wstret': 0.19942021369934082, 'zaskoczenie': 0.00010597382788546383, 'zlosc': 0.7676884531974792, 'neutralny': 0.0001384594797855243}\n",
      "{'oczekiwanie': 0.06689931452274323, 'podziw': 0.056297726929187775, 'radosc': 0.018150344491004944, 'smutek': 0.13493552803993225, 'strach': 0.00028694135835394263, 'wstret': 0.10945132374763489, 'zaskoczenie': 0.0015101212775334716, 'zlosc': 0.6113536953926086, 'neutralny': 0.0011150126811116934}\n",
      "{'oczekiwanie': 0.053864799439907074, 'podziw': 0.0026839866768568754, 'radosc': 0.0010273511288687587, 'smutek': 0.14232219755649567, 'strach': 0.0003101979673374444, 'wstret': 0.08498845249414444, 'zaskoczenie': 0.0005375996115617454, 'zlosc': 0.7137088775634766, 'neutralny': 0.0005565434694290161}\n",
      "{'oczekiwanie': 0.053864799439907074, 'podziw': 0.0026839866768568754, 'radosc': 0.0010273511288687587, 'smutek': 0.14232219755649567, 'strach': 0.0003101979673374444, 'wstret': 0.08498845249414444, 'zaskoczenie': 0.0005375996115617454, 'zlosc': 0.7137088775634766, 'neutralny': 0.0005565434694290161}\n"
     ]
    }
   ],
   "source": [
    "for pred in predictions:\n",
    "    print(pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
