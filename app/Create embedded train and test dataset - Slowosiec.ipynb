{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import sklearn.model_selection\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from transformers import XLMTokenizer, RobertaModel\n",
    "from tqdm import tqdm\n",
    "from helpers import convert_to_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>('emotions',)</th>\n",
       "      <th>('markedness',)</th>\n",
       "      <th>('text',)</th>\n",
       "      <th>('lemma',)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>smutek</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>Za swoje winy został skazany przez sąd na doży...</td>\n",
       "      <td>dożywocie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>zlosc</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>Za swoje winy został skazany przez sąd na doży...</td>\n",
       "      <td>dożywocie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>strach</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>Za swoje winy został skazany przez sąd na doży...</td>\n",
       "      <td>dożywocie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>radosc</td>\n",
       "      <td>0.5</td>\n",
       "      <td>W moim czasie wolnym lubię odpoczywać na dział...</td>\n",
       "      <td>czas wolny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>oczekiwanie</td>\n",
       "      <td>0.5</td>\n",
       "      <td>W moim czasie wolnym lubię odpoczywać na dział...</td>\n",
       "      <td>czas wolny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80406</th>\n",
       "      <td>smutek</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>Po diabelsku potraktowałeś tego człowieka - ni...</td>\n",
       "      <td>po diabelsku</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80407</th>\n",
       "      <td>zlosc</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>Po diabelsku potraktowałeś tego człowieka - ni...</td>\n",
       "      <td>po diabelsku</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80408</th>\n",
       "      <td>wstret</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>Po diabelsku potraktowałeś tego człowieka - ni...</td>\n",
       "      <td>po diabelsku</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80409</th>\n",
       "      <td>wstret</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>A zupka dzisiaj jakaś taka cieniuteńka, jakby ...</td>\n",
       "      <td>cieniuteńki</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80410</th>\n",
       "      <td>wstret</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>Dzisiejszy obiad jakiś taki cieniusieńki, jakb...</td>\n",
       "      <td>cieniusieńki</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80326 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ('emotions',)  ('markedness',)  \\\n",
       "0            smutek             -1.0   \n",
       "1             zlosc             -1.0   \n",
       "2            strach             -1.0   \n",
       "3            radosc              0.5   \n",
       "4       oczekiwanie              0.5   \n",
       "...             ...              ...   \n",
       "80406        smutek             -1.0   \n",
       "80407         zlosc             -1.0   \n",
       "80408        wstret             -1.0   \n",
       "80409        wstret             -0.5   \n",
       "80410        wstret             -0.5   \n",
       "\n",
       "                                               ('text',)    ('lemma',)  \n",
       "0      Za swoje winy został skazany przez sąd na doży...     dożywocie  \n",
       "1      Za swoje winy został skazany przez sąd na doży...     dożywocie  \n",
       "2      Za swoje winy został skazany przez sąd na doży...     dożywocie  \n",
       "3      W moim czasie wolnym lubię odpoczywać na dział...    czas wolny  \n",
       "4      W moim czasie wolnym lubię odpoczywać na dział...    czas wolny  \n",
       "...                                                  ...           ...  \n",
       "80406  Po diabelsku potraktowałeś tego człowieka - ni...  po diabelsku  \n",
       "80407  Po diabelsku potraktowałeś tego człowieka - ni...  po diabelsku  \n",
       "80408  Po diabelsku potraktowałeś tego człowieka - ni...  po diabelsku  \n",
       "80409  A zupka dzisiaj jakaś taka cieniuteńka, jakby ...   cieniuteńki  \n",
       "80410  Dzisiejszy obiad jakiś taki cieniusieńki, jakb...  cieniusieńki  \n",
       "\n",
       "[80326 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_json('../data/slowosiec_data.json.gz', compression='gzip')\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Za swoje winy został skazany przez sąd na dożywocie bez możliwości wcześniejszego warunkowego zwolnienia. \n"
     ]
    }
   ],
   "source": [
    "X = df1[\"('text',)\"].to_numpy()\n",
    "print(X[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert y to onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'smutek'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df1[\"('emotions',)\"].to_numpy()\n",
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 1, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.array([convert_to_onehot(data) for data in y])\n",
    "y[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split dataset with the same label balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = sklearn.model_selection.StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=0)\n",
    "\n",
    "train_X = None\n",
    "test_X = None\n",
    "train_y = None\n",
    "test_y = None\n",
    "\n",
    "for train_index, test_index in splitter.split(X, y):\n",
    "    train_X, test_X = X[train_index], X[test_index]\n",
    "    train_y, test_y = y[train_index], y[test_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get tokenizer and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = XLMTokenizer.from_pretrained(\"allegro/herbert-klej-cased-tokenizer-v1\")\n",
    "model = RobertaModel.from_pretrained(\"allegro/herbert-klej-cased-v1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse datasets into input vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_text(text):\n",
    "    encoded_input = tokenizer.encode(text, return_tensors='pt')\n",
    "    outputs = model(encoded_input)\n",
    "    response = outputs[1].detach().numpy()\n",
    "    return response[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64260/64260 [1:12:37<00:00, 14.75it/s]\n",
      "100%|██████████| 16066/16066 [17:53<00:00, 14.97it/s]\n"
     ]
    }
   ],
   "source": [
    "train_X_parsed = []\n",
    "test_X_parsed = []\n",
    "for x in tqdm(list(train_X)):\n",
    "    train_X_parsed.append(encode_text(x))\n",
    "    \n",
    "for x in tqdm(list(test_X)):\n",
    "    test_X_parsed.append(encode_text(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save parsed data to train and test datasets so i don't have to parse it again!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/slowosiec_train.pickle', 'wb') as handle:\n",
    "    pickle.dump((train_X_parsed, train_y), handle)\n",
    "with open('../data/slowosiec_test.pickle', 'wb') as handle:\n",
    "    pickle.dump((test_X_parsed, test_y), handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/slowosiec_train_org.pickle', 'wb') as handle:\n",
    "    pickle.dump(train_X, handle)\n",
    "with open('../data/slowosiec_test_org.pickle', 'wb') as handle:\n",
    "    pickle.dump(test_X, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
