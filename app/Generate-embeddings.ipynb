{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join\n",
    "import pandas as pd\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "import pickle\n",
    "from transformers import XLMTokenizer, RobertaModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import XLMTokenizer, RobertaModel\n",
    "\n",
    "tokenizer = XLMTokenizer.from_pretrained(\"allegro/herbert-klej-cased-tokenizer-v1\")\n",
    "model = RobertaModel.from_pretrained(\"allegro/herbert-klej-cased-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_df_path = join(\"..\", \"data\", \"slowosiec_all_data.json.gz\")\n",
    "\n",
    "df = pd.read_json(json_df_path)\n",
    "\n",
    "save_path = join(\"..\", \"data\", \"slowosiec_all_data_word_level_embeddingss.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = \"cuda\"\n",
    "\n",
    "# tokenizer = XLMTokenizer.from_pretrained(\"allegro/herbert-klej-cased-tokenizer-v1\")\n",
    "tokenizer = XLMTokenizer.from_pretrained(\"./models/tokenizer/\")\n",
    "\n",
    "# model = RobertaModel.from_pretrained(\"allegro/herbert-klej-cased-v1\")\n",
    "model = RobertaModel.from_pretrained(\"./models/bert/\")\n",
    "\n",
    "model = model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save_pretrained(\"./models/bert/\")\n",
    "# tokenizer.save_pretrained(\"./models/tokenizer/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer.save_pretrained(\"./models/tokenizer/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple, List, Dict\n",
    "import numpy as np\n",
    "\n",
    "def calculate_embeddings(\n",
    "    texts: List[str],\n",
    "    labels: List[str],\n",
    "    emote_to_text: Dict[str, str],\n",
    ") -> Tuple[List[str], List[np.ndarray], List[np.ndarray], List[str]]:\n",
    "\n",
    "    processed_texts = []\n",
    "    sentence_embeddings_list = []\n",
    "    seq_embeddings_list = []\n",
    "    processed_labels = []\n",
    "    \n",
    "    for text, label in tqdm(zip(texts, labels), desc='Encoding texts'):\n",
    "        try:\n",
    "            text = _replace_emotes_with_text(text, emote_to_text)\n",
    "            tokenized = tokenizer.encode(text, return_tensors='pt').to(DEVICE)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                outputs = model(tokenized)\n",
    "                \n",
    "                seq_embedding = outputs[0].squeeze(dim=0).cpu()\n",
    "                sentence_embedding = outputs[1].squeeze(dim=0).cpu()\n",
    "            \n",
    "            processed_texts.append(text)\n",
    "            sentence_embeddings_list.append(sentence_embedding)\n",
    "            seq_embeddings_list.append(seq_embedding)\n",
    "            processed_labels.append(label)\n",
    "\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    return processed_texts, sentence_embeddings_list, seq_embeddings_list, processed_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_texts_embeddings_and_labels(texts):\n",
    "    texts = []\n",
    "    \n",
    "    sentence_embeddings = []\n",
    "    seq_embeddings = []\n",
    "    \n",
    "    for emotion, text in tqdm():\n",
    "        encoded_input = tokenizer.encode(text, return_tensors='pt').to(\"cuda\")\n",
    "        with torch.no_grad():\n",
    "            outputs = model(encoded_input)\n",
    "            sentence_embedding = outputs[1].squeeze(dim=0).cpu()\n",
    "\n",
    "        texts.append(text)\n",
    "        sentence_embeddings.append(sentence_embedding)\n",
    "        emotions.append(emotion)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_texts_embeddings_and_labels(texts):\n",
    "    texts = []\n",
    "    sentence_embeddings = []\n",
    "    seq_embeddings = []\n",
    "    \n",
    "    emotions = []\n",
    "\n",
    "    for emotion, text in tqdm(zip(df[\"('emotions',)\"], df[\"('text',)\"])):\n",
    "        encoded_input = tokenizer.encode(text, return_tensors='pt').to(\"cuda\")\n",
    "        with torch.no_grad():\n",
    "            outputs = model(encoded_input)\n",
    "            sentence_embedding = outputs[1].squeeze(dim=0).cpu()\n",
    "\n",
    "        texts.append(text)\n",
    "        sentence_embeddings.append(sentence_embedding)\n",
    "        emotions.append(emotion)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "839ca2a181564ab8bd6b98a9a728b6d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-293ba9e122e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0msentence_embedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mtexts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "texts = []\n",
    "sentence_embeddings = []\n",
    "emotions = []\n",
    "\n",
    "for emotion, text in tqdm(zip(df[\"('emotions',)\"], df[\"('text',)\"])):\n",
    "    encoded_input = tokenizer.encode(text, return_tensors='pt').to(\"cuda\")\n",
    "    with torch.no_grad():\n",
    "        outputs = model(encoded_input)\n",
    "        sentence_embedding = outputs[1].squeeze(dim=0).cpu()\n",
    "    \n",
    "    texts.append(text)\n",
    "    sentence_embeddings.append(sentence_embedding)\n",
    "    emotions.append(emotion)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
